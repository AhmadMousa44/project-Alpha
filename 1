import os
import sys
import traceback
import customtkinter as ctk
import sounddevice as sd
import numpy as np
import tempfile
import threading
import json
import queue
import time
import requests
from dotenv import load_dotenv
from scipy.io.wavfile import write as write_wav

# === Safe imports with error handling ===
print("Starting Enhanced Jarvis...")
print("Loading environment variables...")
load_dotenv()

# API Keys (some are optional for free services)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
ELEVENLABS_VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")  # Free tier available
HUGGINGFACE_API_KEY = os.getenv("HUGGINGFACE_API_KEY")  # Optional

# Global variables
whisper_model = None
vosk_model = None
elevenlabs_client = None
available_llms = {}
current_llm = None
is_speaking = False
command_queue = queue.Queue()
response_queue = queue.Queue()
audio_device_id = None

class AudioDeviceManager:
    """Manages audio device selection and configuration"""
    
    def __init__(self):
        self.input_devices = []
        self.output_devices = []
        self.selected_input = None
        self.selected_output = None
        self.scan_devices()
    
    def scan_devices(self):
        """Scan and categorize available audio devices"""
        try:
            devices = sd.query_devices()
            self.input_devices = []
            self.output_devices = []
            
            print("\n=== AUDIO DEVICES FOUND ===")
            for i, device in enumerate(devices):
                device_info = f"ID {i}: {device['name']} ({device['max_input_channels']} in, {device['max_output_channels']} out)"
                print(device_info)
                
                if device['max_input_channels'] > 0:
                    self.input_devices.append((i, device['name'], device))
                if device['max_output_channels'] > 0:
                    self.output_devices.append((i, device['name'], device))
            
            # Auto-select best devices
            self.auto_select_devices()
            
        except Exception as e:
            print(f"Error scanning audio devices: {e}")
    
    def auto_select_devices(self):
        """Automatically select the best available devices"""
        # Select input device
        if self.input_devices:
            # Prefer devices with "microphone" or "mic" in name
            for device_id, name, info in self.input_devices:
                if any(keyword in name.lower() for keyword in ['microphone', 'mic', 'input']):
                    self.selected_input = device_id
                    print(f"✓ Auto-selected input: {name}")
                    break
            
            # If no preferred device found, use first available
            if self.selected_input is None:
                self.selected_input = self.input_devices[0][0]
                print(f"✓ Selected input: {self.input_devices[0][1]}")
        
        # Select output device  
        if self.output_devices:
            # Prefer devices with "speaker" or "headphone" in name
            for device_id, name, info in self.output_devices:
                if any(keyword in name.lower() for keyword in ['speaker', 'headphone', 'output']):
                    self.selected_output = device_id
                    print(f"✓ Auto-selected output: {name}")
                    break
            
            # If no preferred device found, use first available
            if self.selected_output is None:
                self.selected_output = self.output_devices[0][0]
                print(f"✓ Selected output: {self.output_devices[0][1]}")
    
    def get_input_device_names(self):
        """Get list of input device names for GUI"""
        return [name for _, name, _ in self.input_devices]
    
    def get_output_device_names(self):
        """Get list of output device names for GUI"""
        return [name for _, name, _ in self.output_devices]
    
    def set_input_device_by_name(self, name):
        """Set input device by name"""
        for device_id, device_name, _ in self.input_devices:
            if device_name == name:
                self.selected_input = device_id
                return True
        return False
    
    def set_output_device_by_name(self, name):
        """Set output device by name"""
        for device_id, device_name, _ in self.output_devices:
            if device_name == name:
                self.selected_output = device_id
                return True
        return False
    
    def test_input_device(self):
        """Test the selected input device"""
        if self.selected_input is None:
            return False, "No input device selected"
        
        try:
            # Test recording for 1 second
            test_audio = sd.rec(
                int(1 * 16000), 
                samplerate=16000, 
                channels=1, 
                dtype='int16',
                device=self.selected_input
            )
            sd.wait()
            
            max_val = np.max(np.abs(test_audio))
            return True, f"Audio level: {max_val}"
            
        except Exception as e:
            return False, f"Test failed: {e}"

class LLMManager:
    """Manages multiple LLM providers with smart fallback"""
    
    def __init__(self):
        self.providers = {}
        self.current_provider = None
        
    def add_provider(self, name, provider):
        """Add an LLM provider"""
        self.providers[name] = provider
        if not self.current_provider:
            self.current_provider = name
    
    def get_response(self, prompt, max_tokens=150):
        """Get response from current provider with fallback"""
        providers_to_try = [self.current_provider] + [p for p in self.providers.keys() if p != self.current_provider]
        
        for provider_name in providers_to_try:
            if provider_name not in self.providers:
                continue
                
            try:
                provider = self.providers[provider_name]
                response = provider.generate(prompt, max_tokens)
                if response:
                    print(f"✓ Response from {provider_name}")
                    return response, provider_name
            except Exception as e:
                print(f"❌ {provider_name} failed: {e}")
                continue
        
        return "I'm having trouble connecting to my AI services right now.", "fallback"

class OllamaProvider:
    """Local Ollama provider (completely free) - Windows 11 optimized"""
    
    def __init__(self, base_url="http://localhost:11434", model="phi3"):
        self.base_url = base_url
        self.model = model
        self.available = self.check_availability()
    
    def check_availability(self):
        try:
            # Check if Ollama is running on Windows
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            models = response.json().get("models", [])
            available_models = [m["name"] for m in models]
            
            # Prefer smaller models for Windows performance
            preferred_models = ["phi3", "llama3.2", "gemma2", "qwen2"]
            
            for preferred in preferred_models:
                if any(preferred in model for model in available_models):
                    self.model = preferred
                    return True
            
            if available_models:
                self.model = available_models[0].split(":")[0]
                return True
            return False
        except Exception as e:
            print(f"Ollama check failed: {e}")
            return False
    
    def generate(self, prompt, max_tokens=150):
        if not self.available:
            raise Exception("Ollama not available")
        
        payload = {
            "model": self.model,
            "prompt": f"You are Jarvis, a helpful AI assistant. Give a brief, conversational response to: {prompt}",
            "stream": False,
            "options": {"num_predict": max_tokens}
        }
        
        response = requests.post(f"{self.base_url}/api/generate", json=payload, timeout=30)
        result = response.json()
        return result.get("response", "").strip()

class GroqProvider:
    """Groq provider (free tier available)"""
    
    def __init__(self, api_key):
        self.api_key = api_key
        self.available = bool(api_key)
    
    def generate(self, prompt, max_tokens=150):
        if not self.available:
            raise Exception("Groq API key not available")
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "messages": [
                {"role": "system", "content": "You are Jarvis, a helpful AI assistant. Give brief, conversational responses."},
                {"role": "user", "content": prompt}
            ],
            "model": "mixtral-8x7b-32768",
            "max_tokens": max_tokens,
            "temperature": 0.7
        }
        
        response = requests.post("https://api.groq.com/openai/v1/chat/completions", 
                               headers=headers, json=payload, timeout=30)
        result = response.json()
        return result["choices"][0]["message"]["content"].strip()

class HuggingFaceProvider:
    """Hugging Face Inference API (free tier available)"""
    
    def __init__(self, api_key=None):
        self.api_key = api_key
        self.model = "microsoft/DialoGPT-medium"
        self.available = True  # Works without API key but with rate limits
    
    def generate(self, prompt, max_tokens=150):
        headers = {}
        if self.api_key:
            headers["Authorization"] = f"Bearer {self.api_key}"
        
        payload = {
            "inputs": f"Human: {prompt}\nJarvis:",
            "parameters": {
                "max_new_tokens": max_tokens,
                "temperature": 0.7,
                "return_full_text": False
            }
        }
        
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{self.model}",
            headers=headers, json=payload, timeout=30
        )
        
        result = response.json()
        if isinstance(result, list) and len(result) > 0:
            return result[0].get("generated_text", "").strip()
        return "Response not available"

class GeminiProvider:
    """Original Gemini provider"""
    
    def __init__(self, api_key):
        self.api_key = api_key
        self.model = None
        self.setup_model()
    
    def setup_model(self):
        if not self.api_key:
            return
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            generation_config = genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=150,
                top_p=0.8,
                top_k=40
            )
            self.model = genai.GenerativeModel("gemini-1.5-flash", generation_config=generation_config)
        except Exception as e:
            print(f"Gemini setup error: {e}")
    
    def generate(self, prompt, max_tokens=150):
        if not self.model:
            raise Exception("Gemini not available")
        response = self.model.generate_content(f"You are Jarvis. Give a brief answer: {prompt}")
        return response.text

def safe_import_and_load():
    """Safely import and load all models with error handling"""
    global whisper_model, vosk_model, elevenlabs_client, available_llms
    
    # Load speech recognition
    try:
        print("Importing Whisper...")
        import whisper
        print("Loading Whisper model...")
        whisper_model = whisper.load_model("tiny")
        print("✓ Whisper loaded successfully")
    except Exception as e:
        print(f"❌ Whisper error: {e}")
        whisper_model = None
    
    # Load TTS
    try:
        print("Importing ElevenLabs...")
        from elevenlabs.client import ElevenLabs
        elevenlabs_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
        print("✓ ElevenLabs loaded successfully")
    except Exception as e:
        print(f"❌ ElevenLabs error: {e}")
        elevenlabs_client = None
    
    # Load Vosk (alternative STT)
    try:
        print("Importing Vosk...")
        from vosk import Model, KaldiRecognizer
        if os.path.exists("model"):
            vosk_model = Model("model")
            print("✓ Vosk loaded successfully")
        else:
            print("❌ Vosk model folder not found")
    except Exception as e:
        print(f"❌ Vosk error: {e}")
        vosk_model = None
    
    # Setup LLM Manager
    llm_manager = LLMManager()
    
    # Add Ollama (local, completely free)
    print("Checking Ollama...")
    ollama = OllamaProvider()
    if ollama.available:
        llm_manager.add_provider("Ollama (Local)", ollama)
        print(f"✓ Ollama loaded with model: {ollama.model}")
    else:
        print("❌ Ollama not available")
        print("   Windows Setup: Download from https://ollama.com/download/windows")
        print("   Then run: ollama pull phi3")
    
    # Add Groq (free tier)
    if GROQ_API_KEY:
        print("Setting up Groq...")
        groq = GroqProvider(GROQ_API_KEY)
        llm_manager.add_provider("Groq (Fast)", groq)
        print("✓ Groq loaded successfully")
    else:
        print("❌ Groq API key not found (get free key at console.groq.com)")
    
    # Add Hugging Face (free tier)
    print("Setting up Hugging Face...")
    hf = HuggingFaceProvider(HUGGINGFACE_API_KEY)
    llm_manager.add_provider("Hugging Face", hf)
    print("✓ Hugging Face loaded successfully")
    
    # Add Gemini (original)
    if GEMINI_API_KEY:
        print("Setting up Gemini...")
        gemini = GeminiProvider(GEMINI_API_KEY)
        if gemini.model:
            llm_manager.add_provider("Gemini", gemini)
            print("✓ Gemini loaded successfully")
    
    available_llms = llm_manager
    return llm_manager

# Initialize audio manager and load everything safely
audio_manager = AudioDeviceManager()
llm_manager = safe_import_and_load()

# === Create Enhanced GUI ===
print("Creating Enhanced GUI...")
try:
    ctk.set_appearance_mode("dark")
    app = ctk.CTk()
    app.geometry("1000x900")
    app.title("Jarvis - Enhanced AI Companion with Audio Fix")

    # Main output area
    output_box = ctk.CTkTextbox(app, wrap="word", font=("Consolas", 12), state="disabled")
    output_box.pack(padx=10, pady=10, fill="both", expand=True)

    # Audio device selection frame
    audio_frame = ctk.CTkFrame(app)
    audio_frame.pack(side="bottom", fill="x", padx=10, pady=5)

    ctk.CTkLabel(audio_frame, text="🎤 Input:", font=("Consolas", 12)).pack(side="left", padx=5)
    
    input_device_names = audio_manager.get_input_device_names()
    if input_device_names:
        input_selector = ctk.CTkOptionMenu(audio_frame, values=input_device_names)
        # Set current selection
        current_input_name = next((name for id, name, _ in audio_manager.input_devices if id == audio_manager.selected_input), input_device_names[0])
        input_selector.set(current_input_name)
        input_selector.pack(side="left", padx=5, fill="x", expand=True)

        def change_input_device(choice):
            if audio_manager.set_input_device_by_name(choice):
                log_to_gui(f"🎤 Switched input to: {choice}")

        input_selector.configure(command=change_input_device)
    else:
        ctk.CTkLabel(audio_frame, text="No input devices found", fg_color="red").pack(side="left", padx=5)

    # LLM selector frame
    llm_frame = ctk.CTkFrame(app)
    llm_frame.pack(side="bottom", fill="x", padx=10, pady=5)

    ctk.CTkLabel(llm_frame, text="🧠 AI Brain:", font=("Consolas", 12)).pack(side="left", padx=5)
    
    llm_options = list(llm_manager.providers.keys()) if llm_manager.providers else ["None Available"]
    llm_selector = ctk.CTkOptionMenu(llm_frame, values=llm_options)
    if llm_manager.current_provider:
        llm_selector.set(llm_manager.current_provider)
    llm_selector.pack(side="left", padx=5, fill="x", expand=True)

    def change_llm(choice):
        llm_manager.current_provider = choice
        log_to_gui(f"🧠 Switched to: {choice}")

    llm_selector.configure(command=change_llm)

    # Status label
    status_label = ctk.CTkLabel(app, text="Status: Starting up...", font=("Consolas", 12))
    status_label.pack(side="bottom", fill="x", pady=2)

    # Enhanced debug info
    available_providers = list(llm_manager.providers.keys()) if llm_manager.providers else []
    debug_info = f"""
ENHANCED DEBUG INFO:
• Whisper: {'✓ Loaded' if whisper_model else '❌ Failed'}
• ElevenLabs: {'✓ Loaded' if elevenlabs_client else '❌ Failed'}
• Vosk: {'✓ Loaded' if vosk_model else '❌ Failed'}
• Available LLMs: {len(available_providers)}
  {' | '.join(available_providers) if available_providers else 'None'}
• Input devices: {len(audio_manager.input_devices)} found
• Selected input: ID {audio_manager.selected_input}
"""
    
    debug_label = ctk.CTkLabel(app, text=debug_info, font=("Consolas", 10), justify="left")
    debug_label.pack(side="bottom", fill="x", pady=2)

    print("✓ Enhanced GUI created successfully")
except Exception as e:
    print(f"❌ GUI creation error: {e}")
    print(traceback.format_exc())
    sys.exit(1)

# === Enhanced Core Functions ===
def log_to_gui(message):
    """Safely log messages to GUI"""
    try:
        app.after(0, lambda: output_box.configure(state="normal"))
        app.after(0, lambda: output_box.insert("end", f"{message}\n"))
        app.after(0, lambda: output_box.see("end"))
        app.after(0, lambda: output_box.configure(state="disabled"))
    except:
        pass

def speak_simple(text):
    """Enhanced TTS function with fallback"""
    global is_speaking
    is_speaking = True
    
    def _speak():
        try:
            if elevenlabs_client:
                audio_data = elevenlabs_client.text_to_speech.convert(
                    voice_id=ELEVENLABS_VOICE_ID,
                    text=text,
                    model_id="eleven_turbo_v2"
                )
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
                    for chunk in audio_data:
                        f.write(chunk)
                    temp_path = f.name

                from pydub import AudioSegment
                segment = AudioSegment.from_file(temp_path, format="mp3")
                data = np.array(segment.get_array_of_samples(), dtype='int16')
                if segment.channels == 2:
                    data = data.reshape((-1, 2))
                
                # Use selected output device if available
                output_device = audio_manager.selected_output if audio_manager.selected_output is not None else None
                sd.play(data, segment.frame_rate, device=output_device)
                sd.wait()
                os.unlink(temp_path)
            else:
                print("TTS not available - would say:", text)
        except Exception as e:
            print(f"TTS error: {e}")
        finally:
            global is_speaking
            is_speaking = False
    
    threading.Thread(target=_speak, daemon=True).start()

def record_and_transcribe():
    """Enhanced record and transcribe function with proper device handling"""
    try:
        if audio_manager.selected_input is None:
            log_to_gui("❌ No input device selected!")
            return

        log_to_gui("🎤 Recording...")
        app.after(0, lambda: status_label.configure(text="Recording..."))
        
        # Record audio with specified device
        duration = 5
        samplerate = 16000
        
        try:
            audio = sd.rec(
                int(duration * samplerate), 
                samplerate=samplerate, 
                channels=1, 
                dtype='int16',
                device=audio_manager.selected_input
            )
            sd.wait()
        except Exception as e:
            log_to_gui(f"❌ Recording failed: {e}")
            log_to_gui("💡 Try selecting a different input device")
            app.after(0, lambda: status_label.configure(text="Recording failed - check device"))
            return
        
        # Check if we got any audio
        max_audio_level = np.max(np.abs(audio))
        if max_audio_level < 100:
            log_to_gui(f"⚠️ Very quiet audio detected (level: {max_audio_level})")
            log_to_gui("💡 Check microphone volume or try speaking louder")
        
        # Save to file
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
            write_wav(f.name, samplerate, audio)
            temp_path = f.name
        
        log_to_gui("🔄 Processing...")
        app.after(0, lambda: status_label.configure(text="Processing..."))
        
        # Transcribe
        if whisper_model:
            result = whisper_model.transcribe(temp_path, language="en")
            query = result["text"].strip()
        else:
            query = "Whisper not available"
        
        os.unlink(temp_path)
        
        if query and len(query) > 3:  # Only process if we got meaningful text
            log_to_gui(f"You: {query}")
            
            # Get enhanced AI response
            try:
                ai_response, provider_used = llm_manager.get_response(query)
                log_to_gui(f"Jarvis ({provider_used}): {ai_response}")
                speak_simple(ai_response)
            except Exception as e:
                error_msg = f"AI Error: {e}"
                log_to_gui(error_msg)
                speak_simple("I encountered an error processing your request.")
        else:
            log_to_gui("❌ No speech detected or transcription failed")
            log_to_gui("💡 Try speaking more clearly or check microphone")
        
        app.after(0, lambda: status_label.configure(text="Ready - Click button to talk"))
        
    except Exception as e:
        error_msg = f"Error: {e}"
        log_to_gui(error_msg)
        print(f"Record/transcribe error: {e}")
        print(traceback.format_exc())
        app.after(0, lambda: status_label.configure(text="Error occurred"))

def test_llm():
    """Test current LLM"""
    try:
        log_to_gui("🧠 Testing AI brain...")
        test_prompt = "Say hello and introduce yourself as Jarvis"
        response, provider = llm_manager.get_response(test_prompt)
        log_to_gui(f"Test Response ({provider}): {response}")
    except Exception as e:
        log_to_gui(f"LLM test failed: {e}")

def test_microphone():
    """Enhanced microphone test with device-specific testing"""
    try:
        if audio_manager.selected_input is None:
            log_to_gui("❌ No input device selected for testing")
            return
            
        log_to_gui("🔧 Testing microphone...")
        log_to_gui("Speak now for 3 seconds...")
        
        success, message = audio_manager.test_input_device()
        
        if success:
            log_to_gui(f"✓ Microphone test successful! {message}")
            if "Audio level:" in message:
                level = int(message.split(":")[1].strip())
                if level < 100:
                    log_to_gui("⚠️ Audio level is low - check microphone volume")
                elif level > 5000:
                    log_to_gui("✓ Good audio level detected")
                else:
                    log_to_gui("✓ Moderate audio level detected")
        else:
            log_to_gui(f"❌ Microphone test failed: {message}")
            log_to_gui("💡 Try selecting a different input device")
            
    except Exception as e:
        log_to_gui(f"Microphone test failed: {e}")

def refresh_audio_devices():
    """Refresh audio device list"""
    try:
        log_to_gui("🔄 Refreshing audio devices...")
        audio_manager.scan_devices()
        
        # Update GUI selectors
        new_input_names = audio_manager.get_input_device_names()
        if new_input_names and hasattr(app, 'input_selector'):
            input_selector.configure(values=new_input_names)
            if audio_manager.selected_input is not None:
                current_name = next((name for id, name, _ in audio_manager.input_devices if id == audio_manager.selected_input), new_input_names[0])
                input_selector.set(current_name)
        
        log_to_gui(f"✓ Found {len(audio_manager.input_devices)} input devices")
        
    except Exception as e:
        log_to_gui(f"Device refresh failed: {e}")

# === Enhanced GUI Buttons ===
button_frame = ctk.CTkFrame(app)
button_frame.pack(side="bottom", fill="x", padx=10, pady=5)

talk_button = ctk.CTkButton(
    button_frame, 
    text="🎤 Talk to Jarvis", 
    command=lambda: threading.Thread(target=record_and_transcribe, daemon=True).start(),
    height=40,
    fg_color="#2B5CE6"
)
talk_button.pack(side="left", padx=5, pady=5, fill="x", expand=True)

test_ai_button = ctk.CTkButton(
    button_frame, 
    text="🧠 Test AI", 
    command=lambda: threading.Thread(target=test_llm, daemon=True).start(),
    height=40,
    fg_color="#10B981"
)
test_ai_button.pack(side="left", padx=5, pady=5)

test_mic_button = ctk.CTkButton(
    button_frame, 
    text="🔧 Test Mic", 
    command=lambda: threading.Thread(target=test_microphone, daemon=True).start(),
    height=40,
    fg_color="#F59E0B"
)
test_mic_button.pack(side="left", padx=5, pady=5)

refresh_button = ctk.CTkButton(
    button_frame, 
    text="🔄 Refresh Audio", 
    command=lambda: threading.Thread(target=refresh_audio_devices, daemon=True).start(),
    height=40,
    fg_color="#8B5CF6"
)
refresh_button.pack(side="right", padx=5, pady=5)

# === Enhanced Startup Messages ===
def startup_messages():
    """Show enhanced startup information"""
    time.sleep(1)  # Wait for GUI to be ready
    
    log_to_gui("=== JARVIS ENHANCED - AUDIO FIXED VERSION ===")
    log_to_gui("🚀 Enhanced with better audio device handling!")
    log_to_gui("")
    
    # Audio device info
    log_to_gui("🎤 Audio Setup:")
    if audio_manager.input_devices:
        log_to_gui(f"   • Found {len(audio_manager.input_devices)} input devices")
        if audio_manager.selected_input is not None:
            current_device = next((name for id, name, _ in audio_manager.input_devices if id == audio_manager.selected_input), "Unknown")
            log_to_gui(f"   • Selected: {current_device}")
        else:
            log_to_gui("   • ⚠️ No input device selected")
    else:
        log_to_gui("   • ❌ No input devices found")
    log_to_gui("")
    
    # AI info
    if llm_manager.providers:
        log_to_gui("✅ AI Systems Available:")
        for provider_name in llm_manager.providers.keys():
            log_to_gui(f"   • {provider_name}")
        log_to_gui("")
        log_to_gui(f"🧠 Current AI: {llm_manager.current_provider}")
        log_to_gui("💡 Switch between AIs using the dropdown menu!")
        log_to_gui("")
        
        if audio_manager.input_devices:
            log_to_gui("✅ Ready! Click 'Talk to Jarvis' to start.")
            log_to_gui("💡 Use 'Test Mic' to verify audio before talking.")
            app.after(0, lambda: status_label.configure(text="Ready - Audio devices configured"))
        else:
            log_to_gui("⚠️ No microphone detected - check audio settings")
            app.after(0, lambda: status_label.configure(text="No microphone - check settings"))
    else:
        log_to_gui("⚠️ No AI providers available. Windows 11 Setup:")
        log_to_gui("  🔸 Ollama (Recommended): Download from ollama.com/download/windows")
        log_to_gui("  🔸 Groq (Fast): Get free API key at console.groq.com")
        log_to_gui("  🔸 Add API keys to your .env file")
        log_to_gui("  🔸 Restart the app after setup")
        app.after(0, lambda: status_label.configure(text="No AI providers - see setup instructions"))
    
    log_to_gui("")
    log_to_gui("🔧 Troubleshooting Tips:")
    log_to_gui("  • If recording fails, try 'Refresh Audio' button")
    log_to_gui("  • Select different input device from dropdown if needed")
    log_to_gui("  • Use 'Test Mic' to check audio levels")
    log_to_gui("  • Ensure microphone permissions are granted")

# Start enhanced startup messages
threading.Thread(target=startup_messages, daemon=True).start()

# === Main App Loop ===
try:
    print("Starting enhanced application...")
    log_to_gui("Starting Enhanced Jarvis...")
    app.mainloop()
except Exception as e:
    print(f"Main loop error: {e}")
    print(traceback.format_exc())
    input("Press Enter to exit...")
